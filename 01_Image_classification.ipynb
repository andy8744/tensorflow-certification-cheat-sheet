{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Image-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2_6mI-_QxJUE",
        "6lwzmRTKxTUv"
      ],
      "authorship_tag": "ABX9TyNulD7QGczSs/sN7k43pRS5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andy8744/tensorflow-certification-cheat-sheet/blob/main/01_Image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "yl6zu7X_LhSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import shutil\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"dark_background\")"
      ],
      "metadata": {
        "id": "nYscU0P5pSIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View random image"
      ],
      "metadata": {
        "id": "3lu-nCFUz9oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "def view_random_image(target_dir, target_class):\n",
        "  target_folder = os.path.join(target_dir, target_class)\n",
        "  random_image = random.sample(os.listdir(target_folder), 1)\n",
        "\n",
        "  img = mpimg.imread(os.path.join(target_folder, random_image[0]))\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\");\n",
        "\n",
        "  print(f\"Image shape: {img.shape}\")\n",
        "  return img"
      ],
      "metadata": {
        "id": "1MfOth67z8ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import PIL\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)\n",
        "roses = list(data_dir.glob('roses/*'))\n",
        "PIL.Image.open(str(roses[0]))"
      ],
      "metadata": {
        "id": "2O0rr4kGIFWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "D3NHW012IPYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset From Directory\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory"
      ],
      "metadata": {
        "id": "8uqM-1LStjiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (224, 224)\n",
        "\n",
        "train_dataset = keras.utils.image_dataset_from_directory(\n",
        "    \"./dataset\", \n",
        "    image_size=image_size,\n",
        "    label_mode=\"int\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        ")\n",
        "\n",
        "val_dataset = keras.utils.image_dataset_from_directory(\n",
        "    \"./dataset\",\n",
        "    image_size=image_size,\n",
        "    label_mode=\"int\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        ")\n",
        "\n",
        "train_dataset = train_dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "POkR1iB9tVGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use shutil to create directory for dataset from directory"
      ],
      "metadata": {
        "id": "ubiP798ybwoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, data in tqdm(test_df.iterrows()):\n",
        "    label = data.label\n",
        "    src = os.path.join(test_src, data.filename)\n",
        "    dest = os.path.join(test_dir, label, data.filename)\n",
        "    shutil.copy(src, dest)"
      ],
      "metadata": {
        "id": "KDjm67jWbvBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in tqdm(os.listdir(\"../input/fingers/train\")):\n",
        "    src = os.path.join(\"../input/fingers/train\", filename)\n",
        "    label = filename.split(\"_\")[1].split(\".\")[0]\n",
        "    dest = os.path.join(\"./train\", label, filename)\n",
        "    shutil.copy(src, dest)"
      ],
      "metadata": {
        "id": "VFMQ3kMrb4u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for subdir in os.listdir(SPLIT_DIR):\n",
        "    print(subdir, len(os.listdir(os.path.join(SPLIT_DIR, subdir))))"
      ],
      "metadata": {
        "id": "jCLMCPA6cZPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Flow from directory"
      ],
      "metadata": {
        "id": "xBkeLfh6JYFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator=datagen.flow_from_dataframe(\n",
        "dataframe=train_df,\n",
        "directory=\"../input/fingers/train\",\n",
        "x_col=\"filename\",\n",
        "y_col=\"label\",\n",
        "batch_size=32,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(128,128))"
      ],
      "metadata": {
        "id": "2AbWDTQKJZBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation Layer"
      ],
      "metadata": {
        "id": "T4V443pZuM3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.2),\n",
        "        layers.RandomZoom(0.2),\n",
        "        layers.RandomContrast(0.2),\n",
        "        layers.RandomHeight(0.2),\n",
        "        layers.RandomWidth(0.2),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "1IE_G-3rvkcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Backbone (USE TRANSFER LEARNING!)"
      ],
      "metadata": {
        "id": "8fYUyGwCvu31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.4),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "6UDBFisQrHNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Rescaling(scale=1./255), # rescale between 0 and 1\n",
        "    \n",
        "    layers.Conv2D(32, 5, activation=\"relu\"),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.BatchNormalization(),  \n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, 3, activation=\"relu\"),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.BatchNormalization(),  \n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(128, 3, activation=\"relu\"),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.BatchNormalization(),  \n",
        "    layers.Dropout(0.25),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    \n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.BatchNormalization(), \n",
        "    layers.Dropout(0.5),\n",
        "  \n",
        "    layers.Dense(10, activation=\"softmax\") \n",
        "])"
      ],
      "metadata": {
        "id": "t6aF3Svivwyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning"
      ],
      "metadata": {
        "id": "YTIh-cFHwT3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Efficientnet B0 (sometimes works)"
      ],
      "metadata": {
        "id": "1GIbJ8Ri1FEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "LqGypI9r1Rw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Xception"
      ],
      "metadata": {
        "id": "2_6mI-_QxJUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.Xception(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))\n",
        "base_model.trainable = False\n",
        "inputs = keras.Input(shape=(150, 150, 3))\n",
        "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
        "x = scale_layer(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "outputs = keras.layers.Dense(3, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "#train\n",
        "base_model.trainable = True\n",
        "#train again lower lr"
      ],
      "metadata": {
        "id": "3gHtSQ9xxSiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MobileNetV2 "
      ],
      "metadata": {
        "id": "6lwzmRTKxTUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "base = MobileNetV2(weights='imagenet', include_top=False)\n",
        "base.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    layers.Rescaling(scale=1.0 / 255.0, offset=-1),\n",
        "    base,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes)\n",
        "])\n"
      ],
      "metadata": {
        "id": "whYDKMV3xVSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Compiling and Fitting"
      ],
      "metadata": {
        "id": "3e05xPaZv1JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Binary\n",
        "METRICS = [\n",
        "tf.keras.metrics.AUC(name='roc-auc'),\n",
        "tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "tf.keras.metrics.Precision(name='precision'),\n",
        "tf.keras.metrics.Recall(name=\"recall\")\n",
        "          ]"
      ],
      "metadata": {
        "id": "rR6kJOrHwEMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "callbacks = [\n",
        "\tEarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True),\n",
        "\tReduceLROnPlateau(monitor='val_loss', min_lr=1e-7, patience=2, mode='min', verbose=1, factor=0.1),\n",
        "\tModelCheckpoint(monitor='val_loss', filepath='./best_model.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "    #metrics=METRICS\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(train_dataset, epochs=100, batch_size=32,\n",
        "\t\t\t\t\tcallbacks=callbacks, validation_data=val_dataset)"
      ],
      "metadata": {
        "id": "2dSAHzP8v43h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict on new data"
      ],
      "metadata": {
        "id": "z2ZNH4dhIl95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
        "sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    sunflower_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "metadata": {
        "id": "V9GQt6wdInZP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}