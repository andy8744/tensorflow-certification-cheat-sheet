{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_Time-Series.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbLBNQLTOf+8gwb6mz55/P"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTlDTxQRNwW1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "plt.style.use(\"dark_background\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### IF CONTAINS DATES\n",
        "df = pd.read_csv(\"/content/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\",\n",
        "                 parse_dates=[\"Date\"],\n",
        "                 index_col=[\"Date\"]) #set Date to become index\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Ya7otR8_OPcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "zrCQ4bOEOL27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "OMmYydWkOSex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "iEhL0P2aOUu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATE TRAIN DF where X is time, Y is values "
      ],
      "metadata": {
        "id": "53k3-BKPOfpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.plot(figsize=(10,7))"
      ],
      "metadata": {
        "id": "ZAXLOk7nOV-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bQxWiBokbb86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps = bitcoin_prices.index.to_numpy()\n",
        "prices = bitcoin_prices[\"Price\"].to_numpy()"
      ],
      "metadata": {
        "id": "Ouyt7O13Owm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train, Test split"
      ],
      "metadata": {
        "id": "5g5Nv7xmO86J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_size = int(0.8*len(prices)) #80% train, 20% test\n",
        "X_train, y_train = timesteps[:split_size], prices[:split_size]\n",
        "X_test, y_test = timesteps[split_size:], prices[split_size:]"
      ],
      "metadata": {
        "id": "hmwpTrEeO7gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train), len(y_train), len(X_test), len(y_test))"
      ],
      "metadata": {
        "id": "THVmv-G5PEMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_time_series(timesteps, values, format=\".\", start=0, end=None, label=None):\n",
        "  plt.plot(timesteps[start:end], values[start:end], format, label=label)\n",
        "  plt.xlabel(\"Time\")\n",
        "  plt.ylabel(\"Price\")\n",
        "  if label:\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.grid(True)"
      ],
      "metadata": {
        "id": "6UPQ80wcO0Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plot_time_series(X_train, y_train, label=\"Train data\")\n",
        "plot_time_series(X_test, y_test, label=\"Test data\")"
      ],
      "metadata": {
        "id": "JonXPUC8O1u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive forecasting"
      ],
      "metadata": {
        "id": "_uNaozJFPQu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "naive_forecast = y_test[:-1] #every value except for the last value\n",
        "naive_forecast[:10], naive_forecast[-10:] # View first 10 and last 10"
      ],
      "metadata": {
        "id": "bu40Q-a8PSfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics"
      ],
      "metadata": {
        "id": "6ykitQ2tPcLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MASE implemented courtesy of sktime - https://github.com/alan-turing-institute/sktime/blob/ee7a06843a44f4aaec7582d847e36073a9ab0566/sktime/performance_metrics/forecasting/_functions.py#L16\n",
        "def mean_absolute_scaled_error(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Implement MASE (assuming no seasonality of data).\n",
        "  \"\"\"\n",
        "  mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
        "\n",
        "  # Find MAE of naive forecast (no seasonality)\n",
        "  mae_naive_no_season = tf.reduce_mean(tf.abs(y_true[1:] - y_true[:-1])) # our seasonality is 1 day (hence the shifting of 1 day)\n",
        "\n",
        "  return mae / mae_naive_no_season"
      ],
      "metadata": {
        "id": "A6g0uGPmPYJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_preds(y_true, y_pred):\n",
        "  # Make sure float32 (for metric calculations)\n",
        "  y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "  y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "\n",
        "  # Calculate various metrics\n",
        "  mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred)\n",
        "  mse = tf.keras.metrics.mean_squared_error(y_true, y_pred) # puts and emphasis on outliers (all errors get squared)\n",
        "  rmse = tf.sqrt(mse)\n",
        "  mape = tf.keras.metrics.mean_absolute_percentage_error(y_true, y_pred)\n",
        "  mase = mean_absolute_scaled_error(y_true, y_pred)\n",
        "  \n",
        "  return {\"mae\": mae.numpy(),\n",
        "          \"mse\": mse.numpy(),\n",
        "          \"rmse\": rmse.numpy(),\n",
        "          \"mape\": mape.numpy(),\n",
        "          \"mase\": mase.numpy()}"
      ],
      "metadata": {
        "id": "ynsj8vOoPbnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_results = evaluate_preds(y_true=y_test[1:], \n",
        "                               y_pred=naive_forecast)\n",
        "naive_results"
      ],
      "metadata": {
        "id": "fS9JLQolPduH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Windowed Dataset"
      ],
      "metadata": {
        "id": "pRUqWqE1PqNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Numpy Method (easiest) https://dev.mrdbourke.com/tensorflow-deep-learning/10_time_series_forecasting_in_tensorflow/#model-7-n-beats-algorithm"
      ],
      "metadata": {
        "id": "7jV_FtoOTMO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labelled_windows(x, horizon=1):\n",
        "  return x[:, :-horizon], x[:, -horizon:]\n",
        "  \n",
        "def make_windows(x, window_size=7, horizon=1):\n",
        "  \"\"\"\n",
        "  Turns a 1D array into a 2D array of sequential windows of window_size.\n",
        "  \"\"\"\n",
        "  # 1. Create a window of specific window_size (add the horizon on the end for later labelling)\n",
        "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
        "  # print(f\"Window step:\\n {window_step}\")\n",
        "\n",
        "  # 2. Create a 2D array of multiple window steps (minus 1 to account for 0 indexing)\n",
        "  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n",
        "  # print(f\"Window indexes:\\n {window_indexes[:3], window_indexes[-3:], window_indexes.shape}\")\n",
        "\n",
        "  # 3. Index on the target array (time series) with 2D array of multiple window steps\n",
        "  windowed_array = x[window_indexes]\n",
        "\n",
        "  # 4. Get the labelled windows\n",
        "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
        "\n",
        "  return windows, labels"
      ],
      "metadata": {
        "id": "8thu_BqyTaOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labelled_windows(x, horizon):\n",
        "  return x[:, :-horizon], x[:, -horizon:]\n",
        "  \n",
        "def make_windows(x, window_size=7, horizon=1):\n",
        "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
        "  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T\n",
        "  windowed_array = x[window_indexes]\n",
        "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
        "\n",
        "  return windows, labels"
      ],
      "metadata": {
        "id": "8mcVKDYGBktj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_windows, full_labels = make_windows(prices, window_size=WINDOW_SIZE, horizon=HORIZON)\n",
        "len(full_windows), len(full_labels)"
      ],
      "metadata": {
        "id": "gvNPJKlJTbms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pandas Method (2nd best method)"
      ],
      "metadata": {
        "id": "aAhTi0BlR8nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HORIZON = 1\n",
        "WINDOW_SIZE = 7\n",
        "\n",
        "# Make a copy of the Bitcoin historical data with block reward feature\n",
        "bitcoin_prices_windowed = bitcoin_prices_block.copy()\n",
        "\n",
        "# Add windowed columns\n",
        "for i in range(WINDOW_SIZE): # Shift values for each step in WINDOW_SIZE\n",
        "  bitcoin_prices_windowed[f\"Price+{i+1}\"] = bitcoin_prices_windowed[\"Price\"].shift(periods=i+1)\n",
        "bitcoin_prices_windowed.head(10)\n",
        "\n",
        "\n",
        "## This might be necessary\n",
        "X_all_flipped = bitcoin_prices_windowed.values\n",
        "\n",
        "for i, value in enumerate(X_all.values):\n",
        "  X_all_flipped[i] = np.flip(value)"
      ],
      "metadata": {
        "id": "QIpbIKL3R_DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the original price/value will become the ground truth\n",
        "X = bitcoin_prices_windowed.dropna().drop(\"Price\", axis=1).astype(np.float32)\n",
        "y = bitcoin_prices_windowed.dropna().Price.astype(np.float32)\n",
        "X.head()"
      ],
      "metadata": {
        "id": "2bG_m9yfSXRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TF window method"
      ],
      "metadata": {
        "id": "V0uwouILT_PD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "\t#series = tf.expand_dims(series, axis=-1) #for Conv1D layers\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "gJ_WY0FnUA09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating windowed dataset with tf.keras.preprocessing.timeseries_dataset_from_array()"
      ],
      "metadata": {
        "id": "df9DHUmvV8M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 7 \n",
        "HORIZON = 1\n",
        "data = bitcoin_prices.values\n",
        "input_data = data[:-WINDOW_SIZE]\n",
        "targets = data[WINDOW_SIZE:]\n",
        "\n",
        "ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data = input_data,\n",
        "    targets = targets,\n",
        "    sequence_length = WINDOW_SIZE,\n",
        ")"
      ],
      "metadata": {
        "id": "Q8Ch6ynYV-Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train test split"
      ],
      "metadata": {
        "id": "jZuiW5IiThEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_train_test_splits(windows, labels, test_split=0.2):\n",
        "  \"\"\"\n",
        "  Splits matching pairs of windows and labels into train and test splits.\n",
        "  \"\"\"\n",
        "  split_size = int(len(windows) * (1-test_split)) # this will default to 80% train/20% test\n",
        "  train_windows = windows[:split_size]\n",
        "  train_labels = labels[:split_size]\n",
        "  test_windows = windows[split_size:]\n",
        "  test_labels = labels[split_size:]\n",
        "  return train_windows, test_windows, train_labels, test_labels"
      ],
      "metadata": {
        "id": "709xg6WLTkGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_windows, test_windows, train_labels, test_labels = make_train_test_splits(full_windows, full_labels)\n",
        "len(train_windows), len(test_windows), len(train_labels), len(test_labels)"
      ],
      "metadata": {
        "id": "uKyDabpCTlkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM Model"
      ],
      "metadata": {
        "id": "ASQRXQqGULtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
        "                      strides=1, padding=\"causal\",\n",
        "                      activation=\"relu\",\n",
        "                      input_shape=[None, 1]),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "  tf.keras.layers.Dense(1),\n",
        "])"
      ],
      "metadata": {
        "id": "BcHy1dvWUNSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\", \"mse\"])\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "callbacks = [\n",
        "\tEarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True),\n",
        "\tReduceLROnPlateau(monitor='val_loss', min_lr=1e-7, patience=2, mode='min', verbose=1, factor=0.1),\n",
        "\tModelCheckpoint(monitor='val_loss', filepath='./best_model.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "model_7.fit(train_dataset, epochs=30, validation_data=test_dataset,\n",
        "            callbacks=[callbacks])"
      ],
      "metadata": {
        "id": "NnjN3M16UklP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}